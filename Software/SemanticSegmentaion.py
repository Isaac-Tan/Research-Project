import os
from tkinter import N
from cv2 import imshow
os. environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import scipy
import numpy
import glob
import matplotlib.pyplot as plt
from matplotlib import colors, cm
from PIL import Image

import tensorflow as tf

from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, SpatialDropout2D, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
import tensorflow.keras.backend as K

data_path = '../Dataset/'

def load_files(path, target_size, scale_factor):    
    image_list = []
    filenames = glob.glob(path)
    filenames.sort()
    for filename in filenames:
        im = Image.open(filename)
        w, h = im.size
        im = im.resize((target_size, target_size))
        im=numpy.asarray(im) / scale_factor
        image_list.append(im)
    return numpy.asarray(image_list)

image_list_train = load_files(data_path + '/images/train/*.jpg', 256, 255.0)
mask_list_train = load_files(data_path + '/masks/train/*.png', 256, 1.0)
mask_list_train = numpy.reshape(mask_list_train, (numpy.shape(mask_list_train) + (1, )))
image_list_test = load_files(data_path + '/images/test/*.jpg', 256, 255.0)
mask_list_test = load_files(data_path + '/masks/test/*.png', 256, 1.0)
mask_list_test = numpy.reshape(mask_list_test, (numpy.shape(mask_list_test) + (1, )))

# print(numpy.shape(image_list_train))
# print(numpy.shape(mask_list_train))
# print(numpy.shape(image_list_test))
# print(numpy.shape(mask_list_test))


def mask_to_categorical(im, num_classes):    
    one_hot_map = []
    for i in range(num_classes):
        class_map = tf.reduce_all(tf.equal(im, i), axis=-1)
        one_hot_map.append(class_map)
    one_hot_map = tf.stack(one_hot_map, axis=-1)
    one_hot_map = tf.cast(one_hot_map, tf.float32)    
    return one_hot_map

def categorical_to_mask(im):
    mask = tf.dtypes.cast(tf.argmax(im, axis=2), 'float32') / 255.0
    return mask

def random_crop(img_x, img_y, random_crop_size):

    height, width = img_x.shape[0], img_x.shape[1]
    dy, dx = random_crop_size
    # x = numpy.random.randint(0, width - dx + 1)
    # y = numpy.random.randint(0, height - dy + 1)
    x = 0
    y = 0
    return img_x[y:(y+dy), x:(x+dx), :], img_y[y:(y+dy), x:(x+dx), :]

def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops_x = numpy.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        batch_crops_y = numpy.zeros((batch_x.shape[0], crop_length, crop_length, 1))
        for i in range(batch_x.shape[0]):
            batch_crops_x[i], batch_crops_y[i] = random_crop(batch_x[i], batch_y[i], (crop_length, crop_length))
        yield (batch_crops_x, mask_to_categorical(batch_crops_y, 2))

batch_size = 32
image_size = 64

train_datagen = ImageDataGenerator(zoom_range=0, horizontal_flip=True)
train_image_generator = train_datagen.flow(image_list_train, batch_size = batch_size, seed=4)
train_mask_generator = train_datagen.flow(mask_list_train, batch_size = batch_size, seed=4)
train_generator = crop_generator(zip(train_image_generator, train_mask_generator), image_size)

val_datagen = ImageDataGenerator(zoom_range=0)
test_image_generator = val_datagen.flow(image_list_test, batch_size = batch_size, seed=4)
test_mask_generator = val_datagen.flow(mask_list_test, batch_size = batch_size, seed=4)
test_generator = crop_generator(zip(test_image_generator, test_mask_generator), image_size)

# Visualise the training and test images & masks
sample = next(train_generator)
# fig = plt.figure(figsize=[5, 4])
# for i,img in enumerate(sample[0]):
#     if (i < 32):
#         ax = fig.add_subplot(8, 8, i*2 + 1)
#         ax.imshow(img, extent=[0, 256, 0, 256])
#         ax = fig.add_subplot(8, 8, i*2 + 2)
#         ax.imshow(categorical_to_mask(sample[1][i,:,:,:]))

test_data, test_gt = next(test_generator)
# fig = plt.figure(figsize=[5, 4])
# for i,img in enumerate(test_data):
#     if (i < 32):
#         ax = fig.add_subplot(8, 8, i*2 + 1)
#         ax.imshow(img, extent=[0, 256, 0, 256])
#         ax = fig.add_subplot(8, 8, i*2 + 2)
#         ax.imshow(categorical_to_mask(test_gt[i,:,:,:]))

# plt.show()

# input, colour images
def model1():
    input_img = Input(shape=(image_size, image_size, 3))

    # encoder, add more filters as we go deeper
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)

    # decoder, reduce filters as we go back up
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)

    # output, 12 channels for 12 classes
    decoded = Conv2D(2, (1, 1), activation='softmax', padding='same')(x)

    segmenter = Model(input_img, decoded)
    print(segmenter.summary())
    return segmenter


def model2():
    input_img = Input(shape=(image_size, image_size, 3))

    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)
    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D((2, 2), padding='same')(conv1)

    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D((2, 2), padding='same')(conv2)

    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D((2, 2), padding='same')(conv3)

    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)

    up1 = UpSampling2D((2, 2))(conv4)
    merge1 = concatenate([conv3,up1], axis = 3)
    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge1)
    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)

    up2 = UpSampling2D((2, 2))(conv5)
    merge2 = concatenate([conv2,up2], axis = 3)
    conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge2)
    conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv6)

    up3 = UpSampling2D((2, 2))(conv6)
    merge3 = concatenate([conv1,up3], axis = 3)
    conv7 = Conv2D(16, (3, 3), activation='relu', padding='same')(merge3)
    conv7 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv7)
    decoded = Conv2D(2, (1, 1), activation='softmax', padding='same')(conv7)

    segmenter = Model(input_img, decoded)
    print(segmenter.summary())
    return segmenter


def focal_loss(target, output, gamma=2):
    output /= K.sum(output, axis=-1, keepdims=True)
    eps = K.epsilon()
    output = K.clip(output, eps, 1. - eps)
    return -K.sum(K.pow(1. - output, gamma) * target * K.log(output), axis=-1)

def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

def create_callbacks():
    scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)
    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto', restore_best_weights=True)
    return [scheduler_callback, early_stopping]

def create_optimiser():
    return tf.keras.optimizers.Adam()
steps_per_epoch = 100
epochs = 1

def visualise(model, test_data, test_gt):
    pred = model.predict(test_data)
    fig = plt.figure(figsize=[5, 4])
    norm = colors.Normalize()
    cmap = cm.hsv
    background = colors.colorConverter.to_rgba('g')
    weed = colors.colorConverter.to_rgba('r')
    for i,img in enumerate(test_data):
        if (i < 32):
            #Original image
            ax = fig.add_subplot(8, 8, i*2 + 1)
            ax.imshow(img)
            #Image with label mask
            # ax = fig.add_subplot(8, 12, i*3 + 2)
            # maskOverlay = cmap(norm(categorical_to_mask(test_gt[i,:,:,:])))
            # maskOverlay[categorical_to_mask(test_gt[i,:,:,:])<=0,:] = background
            # maskOverlay[categorical_to_mask(test_gt[i,:,:,:])>0,:] = weed
            # ax.imshow(img)
            # ax.imshow(maskOverlay, alpha = 0.3)
            #Image with prediction mask
            ax = fig.add_subplot(8, 8, i*2 + 2)
            predOverlay = cmap(norm(categorical_to_mask(pred[i,:,:,:])))
            predOverlay[categorical_to_mask(pred[i,:,:,:])<=0,:] = background
            predOverlay[categorical_to_mask(pred[i,:,:,:])>0,:] = weed
            ax.imshow(img)
            ax.imshow(predOverlay, alpha = 0.3 )

model = model2()
model.compile(optimizer=create_optimiser(), loss=focal_loss, metrics='accuracy')
model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = epochs,
              validation_data=test_generator, validation_steps = 10, callbacks=create_callbacks())
model.evaluate(test_data, test_gt)
visualise(model, test_data, test_gt)
plt.show()